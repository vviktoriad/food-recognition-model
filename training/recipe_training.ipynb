{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VzZ3l22gvq7"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets scikit-learn\n",
        "!pip install hf_xet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "73cTh55dg5FX",
        "outputId": "4db200f0-13d9-439a-d8f6-056693046fb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1bf9b162-eafd-48ab-ad14-820f1092c6af\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1bf9b162-eafd-48ab-ad14-820f1092c6af\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Jedzonko.xlsx to Jedzonko (2).xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "import os\n",
        "from typing import List, Dict  # Dodano typowanie"
      ],
      "metadata": {
        "id": "zGbHGW3ug60Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    df = pd.read_excel(\"Jedzonko.xlsx\")\n",
        "    print(\"Plik załadowano pomyślnie!\")\n",
        "    print(df.head()) # Opcjonalnie, wyświetl kilka pierwszych wierszy\n",
        "except FileNotFoundError:\n",
        "    print(\"Błąd: Nie znaleziono pliku 'Jedzonko.xlsx'. Upewnij się, że został załadowany.\")\n",
        "    exit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeSHbwtFg8tZ",
        "outputId": "b5385374-96ad-417f-e4a0-a52087b92127"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plik załadowano pomyślnie!\n",
            "   Column1                                              Title  \\\n",
            "0        0  Miso-Butter Roast Chicken With Acorn Squash Pa...   \n",
            "1        1                    Crispy Salt and Pepper Potatoes   \n",
            "2        2                        Thanksgiving Mac and Cheese   \n",
            "3        3                 Italian Sausage and Bread Stuffing   \n",
            "4        4                                       Newton's Law   \n",
            "\n",
            "                                        Instructions  \\\n",
            "0  Pat chicken dry with paper towels, season all ...   \n",
            "1  Preheat oven to 400°F and line a rimmed baking...   \n",
            "2  Place a rack in middle of oven; preheat to 400...   \n",
            "3  Preheat oven to 350°F with rack in middle. Gen...   \n",
            "4  Stir together brown sugar and hot water in a c...   \n",
            "\n",
            "                                          Image_Name  \\\n",
            "0  miso-butter-roast-chicken-acorn-squash-panzanella   \n",
            "1         crispy-salt-and-pepper-potatoes-dan-kluger   \n",
            "2         thanksgiving-mac-and-cheese-erick-williams   \n",
            "3          italian-sausage-and-bread-stuffing-240559   \n",
            "4                 newtons-law-apple-bourbon-cocktail   \n",
            "\n",
            "                                 Cleaned_Ingredients  \n",
            "0  ['1 (3½–4-lb.) whole chicken', '2¾ tsp. kosher...  \n",
            "1  ['2 large egg whites', '1 pound new potatoes (...  \n",
            "2  ['1 cup evaporated milk', '1 cup whole milk', ...  \n",
            "3  ['1 (¾- to 1-pound) round Italian loaf, cut in...  \n",
            "4  ['1 teaspoon dark brown sugar', '1 teaspoon ho...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"WANDB_DISABLED\"] = \"true\"  # disable wandb logging"
      ],
      "metadata": {
        "id": "PaqJrqOxg-wV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"t5-base\"  # Zmieniono na większy model\n",
        "OUTPUT_DIR = \"./recipe_model\"\n",
        "LOGGING_DIR = \"./logs\"\n",
        "MAX_INPUT_LENGTH = 128\n",
        "MAX_OUTPUT_LENGTH = 512\n",
        "TRAIN_BATCH_SIZE = 4\n",
        "NUM_TRAIN_EPOCHS = 2  # Zwiększono liczbę epok"
      ],
      "metadata": {
        "id": "svVfsDN7hAM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_ingredients(ingredient_string: str) -> str:\n",
        "    \"\"\"\n",
        "    Czyści listę składników, usuwając nadmiarowe znaki, małe elementy i duplikaty.\n",
        "\n",
        "    Args:\n",
        "        ingredient_string: Ciąg tekstowy zawierający listę składników.\n",
        "\n",
        "    Returns:\n",
        "        Ciąg tekstowy z wyczyszczoną listą składników.\n",
        "    \"\"\"\n",
        "\n",
        "    items = re.split(r',|\\n', str(ingredient_string))\n",
        "    cleaned = []\n",
        "    seen = set()\n",
        "\n",
        "    for item in items:\n",
        "        item = item.strip().lower()\n",
        "        # Rozszerzono warunek czyszczenia\n",
        "        if len(item) > 3 and item not in seen and not re.search(r'\\d+\\s*(g|kg|ml|l|cup|tablespoon|teaspoon|oz)', item):\n",
        "            # Pomijaj składniki, które wyglądają jak ilości (np. \"10g cukru\")\n",
        "            cleaned.append(item)\n",
        "            seen.add(item)\n",
        "\n",
        "    return \"\\n\".join(cleaned)"
      ],
      "metadata": {
        "id": "4dwApkcBhCaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_instructions(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Czyści instrukcje, usuwając nadmiarowe powtórzenia i formatowanie.\n",
        "\n",
        "    Args:\n",
        "        text: Ciąg tekstowy zawierający instrukcje.\n",
        "\n",
        "    Returns:\n",
        "        Ciąg tekstowy z wyczyszczonymi instrukcjami.\n",
        "    \"\"\"\n",
        "\n",
        "    text = re.sub(r'(sugar\\s*,?)+', 'sugar, ', text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r'(sage\\s*,?)+', 'sage, ', text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r'(\\s*,\\s*)+', ', ', text)\n",
        "    text = re.sub(r'(add|stir in|mix in|combine) (sugar|sage)( and \\2)+', r'\\1 \\2', text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r'\\.+', '.', text)  # Usuń wielokrotne kropki\n",
        "    text = re.sub(r'[\\n\\t]+', ' ', text)  # Usuń nowe linie i tabulatory\n",
        "    return text.strip()"
      ],
      "metadata": {
        "id": "FnjgrZUEhFA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(row: pd.Series) -> Dict[str, str]:\n",
        "    \"\"\"\n",
        "    Przygotowuje dane do treningu, łącząc tytuł, składniki i instrukcje.\n",
        "\n",
        "    Args:\n",
        "        row: Wiersz DataFrame zawierający dane przepisu.\n",
        "\n",
        "    Returns:\n",
        "        Słownik zawierający sformatowane dane wejściowe i wyjściowe.\n",
        "    \"\"\"\n",
        "\n",
        "    input_text = f\"generate recipe: {row['Title']}\"\n",
        "    cleaned_ingredients = clean_ingredients(row['Cleaned_Ingredients'])\n",
        "    cleaned_instructions = clean_instructions(str(row['Instructions']))\n",
        "    output_text = f\"Składniki:\\n{cleaned_ingredients}\\n\\nInstrukcje:\\n{cleaned_instructions}\"\n",
        "    return {\"input\": input_text, \"output\": output_text}"
      ],
      "metadata": {
        "id": "EkuNCUlmhFtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Przetwarza DataFrame, przygotowując dane do treningu.\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame zawierający dane przepisów.\n",
        "\n",
        "    Returns:\n",
        "        DataFrame z kolumnami 'input' i 'output' gotowymi do treningu.\n",
        "    \"\"\"\n",
        "    df = df.dropna(subset=['Title', 'Cleaned_Ingredients', 'Instructions'])\n",
        "    data = df.apply(prepare_data, axis=1, result_type='expand')\n",
        "    data.columns = ['input', 'output']\n",
        "    return data"
      ],
      "metadata": {
        "id": "ibf5S5kRhIWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_datasets(data: pd.DataFrame) -> (Dataset, Dataset):\n",
        "    \"\"\"\n",
        "    Dzieli dane na zbiory treningowe i testowe.\n",
        "\n",
        "    Args:\n",
        "        data: DataFrame z danymi.\n",
        "\n",
        "    Returns:\n",
        "        Tuple zawierający zbiory treningowe i testowe jako obiekty Dataset.\n",
        "    \"\"\"\n",
        "    train_data, test_data = train_test_split(data, test_size=0.1, random_state=42)  # Dodano random_state\n",
        "    train_dataset = Dataset.from_pandas(train_data)\n",
        "    test_dataset = Dataset.from_pandas(test_data)\n",
        "    return train_dataset, test_dataset\n"
      ],
      "metadata": {
        "id": "TrI9cE_WhKNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples: Dict[str, List]) -> Dict[str, List[List[int]]]:\n",
        "    \"\"\"\n",
        "    Tokenizuje dane wejściowe i wyjściowe.\n",
        "\n",
        "    Args:\n",
        "        examples: Słownik zawierający listy tekstów wejściowych i wyjściowych.\n",
        "\n",
        "    Returns:\n",
        "        Słownik zawierający tokenizowane dane.\n",
        "    \"\"\"\n",
        "    inputs = tokenizer(examples['input'], padding=\"max_length\", truncation=True, max_length=MAX_INPUT_LENGTH)\n",
        "    labels = tokenizer(examples['output'], padding=\"max_length\", truncation=True, max_length=MAX_OUTPUT_LENGTH)\n",
        "    inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return inputs\n"
      ],
      "metadata": {
        "id": "TUwHJp0ehK3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(train_dataset: Dataset, test_dataset: Dataset) -> T5ForConditionalGeneration:\n",
        "    \"\"\"\n",
        "    Trenuje model T5.\n",
        "\n",
        "    Args:\n",
        "        train_dataset: Zbiór danych treningowych.\n",
        "        test_dataset: Zbiór danych testowych.\n",
        "\n",
        "    Returns:\n",
        "        Wytrenowany model T5.\n",
        "    \"\"\"\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=OUTPUT_DIR,\n",
        "        per_device_train_batch_size=TRAIN_BATCH_SIZE,\n",
        "        num_train_epochs=NUM_TRAIN_EPOCHS,\n",
        "        save_strategy=\"epoch\",\n",
        "        logging_dir=LOGGING_DIR,\n",
        "        logging_steps=10,\n",
        "        fp16=torch.cuda.is_available(),\n",
        "        learning_rate=2e-4,  # Dodano learning rate\n",
        "        weight_decay=0.01,  # Dodano weight decay\n",
        "        gradient_accumulation_steps=2,  # Dodano akumulację gradientu\n",
        "        # evaluation_strategy=\"epoch\", # Włącz ewaluację w trakcie treningu (opcjonalne)\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=test_dataset  # Dodaj test_dataset do ewaluacji (opcjonalne)\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    return model"
      ],
      "metadata": {
        "id": "UXci_NhxhNQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_recipe(model: T5ForConditionalGeneration, tokenizer: T5Tokenizer, input_text: str) -> Dict[str, List[str]]:\n",
        "    \"\"\"\n",
        "    Generuje przepis na podstawie podanego tekstu.\n",
        "\n",
        "    Args:\n",
        "        model: Wytrenowany model T5.\n",
        "        tokenizer: Tokenizer T5.\n",
        "        input_text: Tekst wejściowy, np. \"pizza\".\n",
        "\n",
        "    Returns:\n",
        "        Słownik zawierający listę składników i instrukcje.\n",
        "    \"\"\"\n",
        "\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(model.device)\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        max_length=MAX_OUTPUT_LENGTH,\n",
        "        num_beams=8,  # Zwiększono liczbę belek\n",
        "        no_repeat_ngram_size=3,\n",
        "        early_stopping=True,\n",
        "        temperature=0.8,  # Zwiększono temperaturę\n",
        "        do_sample=True,  # Włączono sampling\n",
        "        top_k=50,  # Dodano top-k sampling\n",
        "        top_p=0.95  # Dodano top-p sampling\n",
        "    )\n",
        "    decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "    parts = decoded_output.split(\"Instrukcje:\")\n",
        "    ingredients = parts[0].replace(\"Składniki:\", \"\").strip().split(\"\\n\")\n",
        "\n",
        "    # Sprawdzanie i czyszczenie instrukcji\n",
        "    if len(parts) > 1:\n",
        "        instructions = parts[1].strip()\n",
        "        instructions = re.sub(r'[\\n\\t]+', ' ', instructions)  # Dodatkowe czyszczenie instrukcji\n",
        "    else:\n",
        "        instructions = \"Brak instrukcji.\"\n",
        "\n",
        "    # Czyszczenie składników\n",
        "    ingredients = [ingredient.strip() for ingredient in ingredients if ingredient.strip()]\n",
        "    ingredients = list(dict.fromkeys(ingredients))  # Usuwanie duplikatów (zachowuje kolejność)\n",
        "\n",
        "    return {\"Składniki\": ingredients, \"Instrukcje\": instructions}\n"
      ],
      "metadata": {
        "id": "-2qmpP__hPje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    import os\n",
        "    from google.colab import files\n",
        "\n",
        "    # Przygotowanie danych\n",
        "    try:\n",
        "        df = pd.read_excel(\"Jedzonko.xlsx\")  # Zmień na nazwę swojego pliku\n",
        "        print(\"Plik załadowano pomyślnie!\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"Błąd: Nie znaleziono pliku. Upewnij się, że plik istnieje i został załadowany.\")\n",
        "        exit()\n",
        "\n",
        "    # Przetwarzanie danych\n",
        "    data = process_dataframe(df)\n",
        "    train_dataset, test_dataset = create_datasets(data)\n",
        "\n",
        "    # Inicjalizacja modelu i tokenizera\n",
        "    tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n",
        "    model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Tokenizacja danych\n",
        "    tokenized_train = train_dataset.map(preprocess_function, batched=True)\n",
        "    tokenized_test = test_dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "    # Trening modelu\n",
        "    trained_model = train_model(tokenized_train, tokenized_test)\n",
        "\n",
        "    # Zapis i pobranie modelu\n",
        "    if trained_model is not None:\n",
        "        trained_model.save_pretrained(\"./recipe_model\")\n",
        "        tokenizer.save_pretrained(\"./recipe_model\")\n",
        "\n",
        "        # Spakowanie do ZIP\n",
        "        os.system('zip -r recipe_model.zip ./recipe_model')\n",
        "\n",
        "        # Pobranie ZIP na komputer (działa tylko w Colab)\n",
        "        files.download(\"recipe_model.zip\")\n",
        "\n",
        "        print(\"Model i tokenizer zostały zapisane i pobrane jako recipe_model.zip\")\n",
        "    else:\n",
        "        print(\"Trening modelu nie został zakończony, więc nie można zapisać modelu.\")"
      ],
      "metadata": {
        "id": "nQ3lgpW0hTip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generowanie przykładowego przepisu\n",
        "    example_input = \"Spanakopita\"\n",
        "    recipe = generate_recipe(trained_model, tokenizer, example_input)\n",
        "    print(f\"Przepis dla: {example_input}\")\n",
        "    print(recipe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMA5teZ1hWQU",
        "outputId": "4fdc2c36-905d-4368-b0d8-759e0e928562"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Składniki': [\"Skadniki: '1 pound Spanakopita' 'kosher salt freshly ground pepper']\"], 'Instrukcje': 'Stir together lime juice, lemon juice, and lime juice in a medium bowl. Season with salt and pepper, then serve with lime wedges garnished with lemon wedges.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"recipe_model.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "MFePWRwHhfPv",
        "outputId": "9d9ff9f7-8501-438d-e5e9-8cf4b10b1d88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ad531a7d-5fa7-4153-abfb-e905886e0fba\", \"recipe_model.zip\", 6628925519)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Cedyi0pmdhQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "!unzip recipe-model.zip\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "vmKkI_Vwhh9V",
        "outputId": "d763ddc5-55c2-4720-d54d-fb21dbfe28f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0de9370b-8a6d-49a4-8153-ff52a7edbebd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0de9370b-8a6d-49a4-8153-ff52a7edbebd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-fcae5f3000a3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unzip recipe-model.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForSeq2SeqLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    165\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    166\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"./recipe_model\"  # adjust path as needed\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_path)"
      ],
      "metadata": {
        "id": "ucXvzgzhhjAC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}